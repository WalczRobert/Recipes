{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d1e857bb-4af6-476e-9be7-f2532ea758c3",
    "_uuid": "d0b5aff7-92ef-4081-bb40-f5fda25e8a98"
   },
   "source": [
    "## Libraries:\n",
    "\n",
    "Below the libraries usedin the analysis. If you get an error while importing a library just ru the following command in your notebook: !pip install packgename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "9ed441bc-0772-449e-9d6f-6c9e4aaac53e",
    "_uuid": "5569f090-521a-4493-8d08-a8d5dd63491a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\rewal\\anaconda3\\lib\\site-packages (0.8)\n",
      "Collecting pyemd\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/c5/7fea8e7a71cd026b30ed3c40e4c5ea13a173e28f8855da17e25271e8f545/pyemd-0.5.1.tar.gz\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from pyemd) (1.17.3)\n",
      "Building wheels for collected packages: pyemd\n",
      "  Building wheel for pyemd (setup.py): started\n",
      "  Building wheel for pyemd (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyemd\n",
      "Failed to build pyemd\n",
      "Installing collected packages: pyemd\n",
      "    Running setup.py install for pyemd: started\n",
      "    Running setup.py install for pyemd: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\rewal\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-44wlpn3k\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-44wlpn3k\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-wheel-zryswd1i' --python-tag cp37\n",
      "       cwd: C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-install-44wlpn3k\\pyemd\\\n",
      "  Complete output (11 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win32-3.7\n",
      "  creating build\\lib.win32-3.7\\pyemd\n",
      "  copying pyemd\\__about__.py -> build\\lib.win32-3.7\\pyemd\n",
      "  copying pyemd\\__init__.py -> build\\lib.win32-3.7\\pyemd\n",
      "  running build_ext\n",
      "  building 'pyemd.emd' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyemd\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\rewal\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-44wlpn3k\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-44wlpn3k\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-record-ix7wumg3\\install-record.txt' --single-version-externally-managed --compile\n",
      "         cwd: C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-install-44wlpn3k\\pyemd\\\n",
      "    Complete output (11 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win32-3.7\n",
      "    creating build\\lib.win32-3.7\\pyemd\n",
      "    copying pyemd\\__about__.py -> build\\lib.win32-3.7\\pyemd\n",
      "    copying pyemd\\__init__.py -> build\\lib.win32-3.7\\pyemd\n",
      "    running build_ext\n",
      "    building 'pyemd.emd' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\rewal\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-44wlpn3k\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-44wlpn3k\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-record-ix7wumg3\\install-record.txt' --single-version-externally-managed --compile Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in c:\\users\\rewal\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from langid) (1.17.3)\n",
      "Collecting pyemd\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/c5/7fea8e7a71cd026b30ed3c40e4c5ea13a173e28f8855da17e25271e8f545/pyemd-0.5.1.tar.gz\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from pyemd) (1.17.3)\n",
      "Building wheels for collected packages: pyemd\n",
      "  Building wheel for pyemd (setup.py): started\n",
      "  Building wheel for pyemd (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyemd\n",
      "Failed to build pyemd\n",
      "Installing collected packages: pyemd\n",
      "    Running setup.py install for pyemd: started\n",
      "    Running setup.py install for pyemd: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\rewal\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxh6zn2w\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxh6zn2w\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-wheel-2i2dgbo2' --python-tag cp37\n",
      "       cwd: C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-install-hxh6zn2w\\pyemd\\\n",
      "  Complete output (11 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win32-3.7\n",
      "  creating build\\lib.win32-3.7\\pyemd\n",
      "  copying pyemd\\__about__.py -> build\\lib.win32-3.7\\pyemd\n",
      "  copying pyemd\\__init__.py -> build\\lib.win32-3.7\\pyemd\n",
      "  running build_ext\n",
      "  building 'pyemd.emd' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyemd\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\rewal\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxh6zn2w\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxh6zn2w\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-record-pf3x1hb9\\install-record.txt' --single-version-externally-managed --compile\n",
      "         cwd: C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-install-hxh6zn2w\\pyemd\\\n",
      "    Complete output (11 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win32-3.7\n",
      "    creating build\\lib.win32-3.7\\pyemd\n",
      "    copying pyemd\\__about__.py -> build\\lib.win32-3.7\\pyemd\n",
      "    copying pyemd\\__init__.py -> build\\lib.win32-3.7\\pyemd\n",
      "    running build_ext\n",
      "    building 'pyemd.emd' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\rewal\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxh6zn2w\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\rewal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxh6zn2w\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\rewal\\AppData\\Local\\Temp\\pip-record-pf3x1hb9\\install-record.txt' --single-version-externally-managed --compile Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inflect in c:\\users\\rewal\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from inflect) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->inflect) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->inflect) (8.0.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\rewal\\anaconda3\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from gensim) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from gensim) (1.17.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from gensim) (1.13.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.12.39)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.15.39)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\rewal\\anaconda3\\lib\\site-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt\n",
    "!pip install pyemd\n",
    "!pip install langid\n",
    "!pip install pyemd\n",
    "!pip install inflect\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_cell_guid": "e7f988a6-d886-448e-84ce-2f63b51c3c95",
    "_uuid": "437ead11-e2cb-4977-8d21-ce57fffe23aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rewal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "from bs4 import BeautifulSoup \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import langid\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "723aa1a4-5a6f-4d49-ad12-67ab9f31fcfe",
    "_uuid": "83bb8c62-04b8-4972-a945-f2546a1dec2e"
   },
   "source": [
    "## Data loading: \n",
    "This cell allow me to know the subfolders of my input since I'm working on kaggle kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_cell_guid": "1e808bcc-7536-4f60-bdba-57bce3b6fbd6",
    "_uuid": "04cc9cfc-3895-4f0d-9693-34f281474fb7"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a7cf4ce3b0bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the path of the files while loading them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "56c1b808-819f-44be-9cb4-8b767cd6478c",
    "_uuid": "cc35581d-3c34-4d1e-9676-884d00c4db3f"
   },
   "outputs": [],
   "source": [
    "#Reading the test cases \n",
    "Data = pd.read_csv(\"C:\\\\Users\\\\rewal\\\\Downloads\\\\NLPtask\\\\1000_case_text.csv\")\n",
    "\n",
    "#Reading the word documents\n",
    "doc1 = docx2txt.process(\"C:\\\\Users\\\\rewal\\\\Downloads\\\\NLPtask\\\\JD_AMS_Corpus_1.docx\")\n",
    "#doc2 = docx2txt.process(\"C:\\\\Users\\\\rewal\\\\Downloads\\\\NLPtask\\\\Document_2.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa061e2d-8830-4da6-916f-d391030b6996",
    "_uuid": "598b7974-89c3-4b97-a184-df47c891a22b"
   },
   "source": [
    "## Data Cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined two cleaning fuctions: one for word documents and one for test cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_cell_guid": "f50d70a9-88e8-4106-b91b-6dbe15386ec6",
    "_uuid": "093f5d2f-9671-4b27-83ec-97c78d2b82f0"
   },
   "outputs": [],
   "source": [
    "#Preprocessing function: \n",
    "\n",
    "contraction = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                 \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                 \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                  \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                  \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                  \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                  \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                  \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                   \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                   \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                   \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                   \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                   \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                   \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                   \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                    \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                    \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "def textprocessing(text): \n",
    "    Text = text.lower() # Convert everything to lowercase\n",
    "    Text = BeautifulSoup(Text, \"lxml\").text #Remove HTML tags: Extract text from tags \n",
    "    Text = re.sub(r'\\([^)]*\\)', '', Text) # Remove any text inside the parenthesis\n",
    "    Text = re.sub('\"','', Text) \n",
    "    Text = ' '.join([contraction[t] if t in contraction else t for t in Text.split(\" \")])    \n",
    "    Text = re.sub(r\"'s\\b\",\"\",Text)  #Remove (‘s) \\b: Returns a match where the specified characters are at the beginning or at the end of a word\n",
    "    Text = re.sub(\"[^a-zA-Z]\", \" \", Text)\n",
    "    tokens = [w for w in Text.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                  #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "67f274f4-d740-45d3-8449-f2c71c409825",
    "_uuid": "2da50b91-7f9f-4966-88c3-132238a79c74"
   },
   "source": [
    "### A -  Word documents preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ones we load the data, we feed it into a processing part which consists of several steps:\n",
    "We define a processing function that includes all the following sub functions:\n",
    "\n",
    " - Convert the reviews and summaries to lowercase\n",
    " - Remove HTML tags\n",
    " - Contraction mapping: that consists of importing a contraction dictionary for example: did'nt ~ did not\n",
    " - Remove (‘s)\n",
    " - Remove any text inside the parenthesis ( )\n",
    " - Eliminate punctuations and special characters\n",
    " - Eliminate stop words\n",
    " - Eliminate short words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_cell_guid": "7a281643-381c-4ec3-beb5-2a3786e3f1f5",
    "_uuid": "b5dd0ea9-69aa-4b88-a431-9c62c1941ffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180195"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanedW1 = textprocessing(doc1)\n",
    "#CleanedW2 = textprocessing(doc2)\n",
    "#file1 = open(\"MyFile.txt\",\"a\") \n",
    "#file1.write(CleanedW1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "329bea41-aadd-4845-a2d9-3080cea6f047",
    "_uuid": "7bb09496-97f1-4178-9029-056abd127e2e"
   },
   "source": [
    "### B - Test cases preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test cases processing includes the following functions: \n",
    "\n",
    "* removing non asci words\n",
    "* replacing numbers with strings: 2 becomes two...\n",
    "* Setting the whole text into lowercase\n",
    "* removing punctuation\n",
    "* remove stopwords like articles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_cell_guid": "d4f4e4a2-ca28-483c-b369-0acb3fea4a56",
    "_uuid": "d3e89002-4c64-4383-9e67-331c498862ae"
   },
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import inflect\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    remove_non_ascii(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return ' '.join(word for word in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "50169962-048e-4c7e-90b8-920e883a491e",
    "_uuid": "0a899ccf-39eb-45a0-94d5-8478d4d5e7fb"
   },
   "source": [
    "### Test cases tokenization: \n",
    "\n",
    "The texts are written with different languages and since the packages used for text processing and modeling include language in their functions we must work with each set of texts seperatly ( by language). Therefore, we used the langid function to verify the language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_cell_guid": "66622a43-a940-4623-a8e2-3324190e98fb",
    "_uuid": "ed1344c9-bd11-4ee7-b511-66ab9374ac46"
   },
   "outputs": [],
   "source": [
    "#We get rows where the variable 'CNSLD_EXTRN_CMNT' in not NA\n",
    "DATA  = Data[Data['CNSLD_EXTRN_CMNT'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_cell_guid": "e39e2c20-252b-4c5b-a8b5-79183ef68379",
    "_uuid": "78d7f80e-be6b-4349-b5f1-98dd506157bb"
   },
   "outputs": [],
   "source": [
    "EnData = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rewal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "fa91a783-7907-4027-8b4a-cc7d1954b755",
    "_uuid": "44e27e46-9f5c-49b4-a05f-9a8bbf6fc94e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v = DATA.shape[0]\n",
    "a=0\n",
    "for i in range(v):\n",
    "    if langid.classify(DATA.iloc[i][3])[0] == 'en':\n",
    "        EnData = EnData.append(DATA.iloc[i])\n",
    "        a=a+i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fb8811c0-01d7-409b-9e7e-2ef8042dd9b9",
    "_uuid": "1acebc72-ffc0-4b64-8f41-9b584e990664"
   },
   "source": [
    "#### Tokenization:\n",
    "It refers to splitting the text into words since the normalize fucntion takes as input list of words and not text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_cell_guid": "82bac5fb-1d2d-44ef-8bff-a6f2ab0cc7fe",
    "_uuid": "5ce6f5cc-e6a5-443c-b597-22b3e7b1dbd4"
   },
   "outputs": [],
   "source": [
    "TokensTests = [word_tokenize(i) for i in EnData['CNSLD_EXTRN_CMNT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_cell_guid": "10fd5d20-98bc-4267-b375-181c2fcd73d2",
    "_uuid": "5468cac2-1500-41a4-9e73-8dd5b0506ee8"
   },
   "outputs": [],
   "source": [
    "CleanedTEXT = []\n",
    "for t in TokensTests:\n",
    "    CleanedTEXT.append(normalize(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "faf08a31-afb6-4447-8d75-5173a04ef66a",
    "_uuid": "1cfeafb2-dfd2-4c8b-9901-84bd8de1a2b1"
   },
   "source": [
    "EnData['CleanedText']=CleanedTEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'EnData' data frame contains the cleaned text tat ill be fed into our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "fa6bc26a-bf47-4dff-8082-ca2dcdb3b33e",
    "_uuid": "32638d6b-1948-4609-be00-a459dfd0ee1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>CASE_SMRY</th>\n",
       "      <th>CNSLD_EXTRN_CMNT</th>\n",
       "      <th>CNSLD_INTRN_CMNT</th>\n",
       "      <th>DEL_IND</th>\n",
       "      <th>EDL_LOAD_TS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTAC-836068</td>\n",
       "      <td>JHB // hydraulic surge scv</td>\n",
       "      <td>Lewis:We are seeing normal here.The charge der...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTAC-836134</td>\n",
       "      <td>523628.10 (def dosing pressure abnormal) /ques...</td>\n",
       "      <td>Ben,Reference attached Solution 117649, John D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTAC-836152</td>\n",
       "      <td>as code 629.13</td>\n",
       "      <td>DTAC: Called and Spoke with Harold. The softwa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTAC-836198</td>\n",
       "      <td>Bad ecu,need payload information,</td>\n",
       "      <td>DTAC:  Hello Edward. If You are getting error ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTAC-83635</td>\n",
       "      <td>Failed fuel sensor</td>\n",
       "      <td>thanks feedback case to us On this tractor fue...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CASE_ID                                          CASE_SMRY  \\\n",
       "0  DTAC-836068                         JHB // hydraulic surge scv   \n",
       "1  DTAC-836134  523628.10 (def dosing pressure abnormal) /ques...   \n",
       "2  DTAC-836152                                     as code 629.13   \n",
       "3  DTAC-836198                  Bad ecu,need payload information,   \n",
       "4   DTAC-83635                                 Failed fuel sensor   \n",
       "\n",
       "                                    CNSLD_EXTRN_CMNT CNSLD_INTRN_CMNT  \\\n",
       "0  Lewis:We are seeing normal here.The charge der...              NaN   \n",
       "1  Ben,Reference attached Solution 117649, John D...              NaN   \n",
       "2  DTAC: Called and Spoke with Harold. The softwa...              NaN   \n",
       "3  DTAC:  Hello Edward. If You are getting error ...              NaN   \n",
       "4  thanks feedback case to us On this tractor fue...             None   \n",
       "\n",
       "   DEL_IND   EDL_LOAD_TS  \n",
       "0      0.0  1.583593e+09  \n",
       "1      0.0  1.583593e+09  \n",
       "2      0.0  1.583593e+09  \n",
       "3      0.0  1.583593e+09  \n",
       "4      0.0  1.583593e+09  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EnData.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdc3fbc6-abda-4375-ba28-024fd3029873",
    "_uuid": "fcf0be8d-ca6c-45d1-a1b1-942e9ab3487d"
   },
   "source": [
    "## Modeling: \n",
    "We will quantify the meaning similarity between the test cases and the word documents using pretrained word2vec model. \n",
    "In this context, we worked with pre-trained word embedding model 'Word2vec' trained on Google News to get the vector representations for each text's word either in the test file and word doc one. Therefore, we are facing a problem of similarity computing presented as follows.\n",
    "\n",
    "Suppose we want to calculate the similarity between those two sentences:\n",
    "\n",
    "𝑆1  = 'obama speaks media illinois' ,  𝑆2  = 'president greets press chicago'\n",
    "It is true that those sentences don't share the same words but maybe they conveyed the same information. At this stage, each sentence is represented as a matrix but the question that arises how could you make a match between the similar words belonging to each sentence. For example, How could you associate Obama to president?\n",
    "\n",
    "Consequently, we use Word Moving Distance optimization algorithm inspired from the usual optimization problem Earth Mover Distance. It allows transfer every word from sentence 1 to sentence 2 because algorithm does not know “obama” should transfer to “president”. At the end it will choose the minimum transportation cost to transport every word from sentence 1 to sentence 2.\n",
    "\n",
    "By analogy, we will aplly it in our case study by considering S1 : test case and S2: word doc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load pretrained word2vec word embedding using gensim library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_cell_guid": "9bd599f0-3443-46c0-947e-c6d6afcb6067",
    "_uuid": "28dd3f77-0383-43e0-a0c3-767c570de8e8"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-cdbe4c16f48e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# df1 = df[['Engine Fuel Type','Transmission Type','Driven_Wheels','Market Category','Vehicle Size', 'Vehicle Style', 'Maker_Model']]# For each row, combine all the columns into one column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# df2 = df1.apply(lambda x: ','.join(x.astype(str)), axis=1)# Store them in a pandas dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_clean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'CleanedText'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mEnData\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Create the list of list format of the custom corpus for gensim modeling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CleanedText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    409\u001b[0m             )\n\u001b[0;32m    410\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         ]\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "# Select features from original dataset to form a new dataframe \n",
    "# df1 = df[['Engine Fuel Type','Transmission Type','Driven_Wheels','Market Category','Vehicle Size', 'Vehicle Style', 'Maker_Model']]# For each row, combine all the columns into one column\n",
    "# df2 = df1.apply(lambda x: ','.join(x.astype(str)), axis=1)# Store them in a pandas dataframe\n",
    "df_clean = pd.DataFrame({'CleanedText': EnData})# Create the list of list format of the custom corpus for gensim modeling \n",
    "sent = [row.split(',') for row in df_clean['CleanedText']]\n",
    "model = Word2Vec(sent, min_count=1,size= 50,workers=3, window =3, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_cell_guid": "50ca702e-8208-47a7-af61-51aa38c4e7ba",
    "_uuid": "503ad58c-0bb4-46a7-a88a-855602451d23"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-94-5ca133dbfb18>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-94-5ca133dbfb18>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    model = gensim.models.KeyedVectors.load_word2vec_format('C:\\Users\\rewal\\Downloads\\NLPtask\\MyFile.txt', binary=false, encoding = \"ISO-8859-1\")\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('C:\\Users\\rewal\\Downloads\\NLPtask\\MyFile.txt', binary=false, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "d380d591-687d-42c3-8fbe-24834724a44b",
    "_uuid": "1d2016d3-b94b-4971-9977-f2419fc6843a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'solution number solution summary active implement guidance igrade connect mobile planting surface water pro function using universal receiver tractor integrated receiver publication date mar paper copies solutions may current solutions complaint symptom igrade max cut feature function connected integrated receiver active implement guidance function connected integrated receiver connect mobile function connected integrated receiver surface water pro function connected integrated receiver problem situation connected integrated receiver using universal receiver app controller looking wrong source address receiver information integrated receiver claim source address moves universal receiver following normal iso address claiming rules app controller looks source address receiver information connected integrated receiver using universal receiver connect mobile wireless data server look integrated receiver located source however receiver stops transmitting data bus since universal starfire added universal starfire providing gps position data system wds ignoring favor integrated receiver since wds seeing starfire data connect mobile planting function surface water pro supported tractors integrated receiver solution update march software update available application controller resolve issue active implement guidance igrade software version ucc ucc downloaded software bundle using software manager live update isg engineering aware remaining incompatibilities working towards solution using universal receiver disconnect integrated receiver behind radio following steps tractor technical manual picture additional information'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanedW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e8cf20d4-41d9-4bc3-a64e-dde4c2f1ce12",
    "_uuid": "1a9d398d-33d2-412c-9e20-042c347b4e3c"
   },
   "source": [
    "## Exmample of distance computing\n",
    "We feed into wmd function two sentences similar in meaning. More similar they are, the distance converged t 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "bcb0f892-c721-4b26-bb01-4f64bd64ded2",
    "_uuid": "fba37803-1aad-41c4-b3d3-4ab80837991f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752898828221336"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.init_sims(replace=True)\n",
    "S1= 'beauty of nature'\n",
    "S2 ='her beauty is natural'\n",
    "model.wmdistance(S1, S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "892de2cb-1b65-40b0-b6ca-3cda277db154",
    "_uuid": "eb68ff35-05c2-4d17-9008-1c07dc12168c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3769468686540851"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.init_sims(replace=True)\n",
    "model.wmdistance(EnData['CleanedText'][0], CleanedW2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "d6f5c6a7-75ef-45cb-b1bb-8d8096959d9f",
    "_uuid": "54b553e9-834e-479c-afb8-1eb15e0704d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>CASE_SMRY</th>\n",
       "      <th>CNSLD_EXTRN_CMNT</th>\n",
       "      <th>CNSLD_INTRN_CMNT</th>\n",
       "      <th>DEL_IND</th>\n",
       "      <th>EDL_LOAD_TS</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTAC-836068</td>\n",
       "      <td>JHB // hydraulic surge scv</td>\n",
       "      <td>Lewis:We are seeing normal here.The charge der...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>lewis seeing normal herethe charge derate soft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTAC-836134</td>\n",
       "      <td>523628.10 (def dosing pressure abnormal) /ques...</td>\n",
       "      <td>Ben,Reference attached Solution 117649, John D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>ben reference attached solution one hundred an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTAC-836152</td>\n",
       "      <td>as code 629.13</td>\n",
       "      <td>DTAC: Called and Spoke with Harold. The softwa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>dtac called spoke harold software updated prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTAC-836198</td>\n",
       "      <td>Bad ecu,need payload information,</td>\n",
       "      <td>DTAC:  Hello Edward. If You are getting error ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>dtac hello edward getting error 1057037 please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTAC-83635</td>\n",
       "      <td>Failed fuel sensor</td>\n",
       "      <td>thanks feedback case to us On this tractor fue...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>thanks feedback case us tractor fuel level sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CASE_ID                                          CASE_SMRY  \\\n",
       "0  DTAC-836068                         JHB // hydraulic surge scv   \n",
       "1  DTAC-836134  523628.10 (def dosing pressure abnormal) /ques...   \n",
       "2  DTAC-836152                                     as code 629.13   \n",
       "3  DTAC-836198                  Bad ecu,need payload information,   \n",
       "4   DTAC-83635                                 Failed fuel sensor   \n",
       "\n",
       "                                    CNSLD_EXTRN_CMNT CNSLD_INTRN_CMNT  \\\n",
       "0  Lewis:We are seeing normal here.The charge der...              NaN   \n",
       "1  Ben,Reference attached Solution 117649, John D...              NaN   \n",
       "2  DTAC: Called and Spoke with Harold. The softwa...              NaN   \n",
       "3  DTAC:  Hello Edward. If You are getting error ...              NaN   \n",
       "4  thanks feedback case to us On this tractor fue...             None   \n",
       "\n",
       "   DEL_IND   EDL_LOAD_TS                                        CleanedText  \n",
       "0      0.0  1.583593e+09  lewis seeing normal herethe charge derate soft...  \n",
       "1      0.0  1.583593e+09  ben reference attached solution one hundred an...  \n",
       "2      0.0  1.583593e+09  dtac called spoke harold software updated prog...  \n",
       "3      0.0  1.583593e+09  dtac hello edward getting error 1057037 please...  \n",
       "4      0.0  1.583593e+09  thanks feedback case us tractor fuel level sho...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EnData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cfb2f8e-5825-4dde-ba1b-79c80006dd85",
    "_uuid": "90fce1ae-33f3-41b4-9fcc-68ddcd63aa41"
   },
   "source": [
    "We compute the similarity between word document1 (Word document2) and all the test cases. They are represented by 'SimW1' and 'SimW2' in the 'EnData' dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "3698b975-f7b7-4b5c-9bff-9ac583ddd797",
    "_uuid": "3930a557-1faf-4f52-92e0-b7a11dfbbc4f"
   },
   "outputs": [],
   "source": [
    "N=EnData.shape[0]\n",
    "SimEvaluation1 =[]\n",
    "SimEvaluation2=[]\n",
    "#model.init_sims(replace=True)\n",
    "for i in range(N): \n",
    "    SimEvaluation1.append(model.wmdistance(EnData.iloc[i]['CleanedText'], CleanedW1))\n",
    "    SimEvaluation2.append(model.wmdistance(EnData.iloc[i]['CleanedText'], CleanedW2))\n",
    "\n",
    "EnData['SimW1']=SimEvaluation1\n",
    "EnData['SimW2'] = SimEvaluation2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "648f479b-f7a0-493d-96e0-03ddd76a8dba",
    "_uuid": "2ee11d1e-96d1-40ce-b2e6-80ea1dbf68ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>CASE_SMRY</th>\n",
       "      <th>CNSLD_EXTRN_CMNT</th>\n",
       "      <th>CNSLD_INTRN_CMNT</th>\n",
       "      <th>DEL_IND</th>\n",
       "      <th>EDL_LOAD_TS</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>SimW1</th>\n",
       "      <th>SimW2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTAC-836068</td>\n",
       "      <td>JHB // hydraulic surge scv</td>\n",
       "      <td>Lewis:We are seeing normal here.The charge der...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>lewis seeing normal herethe charge derate soft...</td>\n",
       "      <td>0.445538</td>\n",
       "      <td>0.376947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTAC-836134</td>\n",
       "      <td>523628.10 (def dosing pressure abnormal) /ques...</td>\n",
       "      <td>Ben,Reference attached Solution 117649, John D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>ben reference attached solution one hundred an...</td>\n",
       "      <td>0.390369</td>\n",
       "      <td>0.410178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTAC-836152</td>\n",
       "      <td>as code 629.13</td>\n",
       "      <td>DTAC: Called and Spoke with Harold. The softwa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>dtac called spoke harold software updated prog...</td>\n",
       "      <td>0.441620</td>\n",
       "      <td>0.496341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTAC-836198</td>\n",
       "      <td>Bad ecu,need payload information,</td>\n",
       "      <td>DTAC:  Hello Edward. If You are getting error ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>dtac hello edward getting error 1057037 please...</td>\n",
       "      <td>0.394192</td>\n",
       "      <td>0.428796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTAC-83635</td>\n",
       "      <td>Failed fuel sensor</td>\n",
       "      <td>thanks feedback case to us On this tractor fue...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583593e+09</td>\n",
       "      <td>thanks feedback case us tractor fuel level sho...</td>\n",
       "      <td>0.600068</td>\n",
       "      <td>0.614462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CASE_ID                                          CASE_SMRY  \\\n",
       "0  DTAC-836068                         JHB // hydraulic surge scv   \n",
       "1  DTAC-836134  523628.10 (def dosing pressure abnormal) /ques...   \n",
       "2  DTAC-836152                                     as code 629.13   \n",
       "3  DTAC-836198                  Bad ecu,need payload information,   \n",
       "4   DTAC-83635                                 Failed fuel sensor   \n",
       "\n",
       "                                    CNSLD_EXTRN_CMNT CNSLD_INTRN_CMNT  \\\n",
       "0  Lewis:We are seeing normal here.The charge der...              NaN   \n",
       "1  Ben,Reference attached Solution 117649, John D...              NaN   \n",
       "2  DTAC: Called and Spoke with Harold. The softwa...              NaN   \n",
       "3  DTAC:  Hello Edward. If You are getting error ...              NaN   \n",
       "4  thanks feedback case to us On this tractor fue...             None   \n",
       "\n",
       "   DEL_IND   EDL_LOAD_TS                                        CleanedText  \\\n",
       "0      0.0  1.583593e+09  lewis seeing normal herethe charge derate soft...   \n",
       "1      0.0  1.583593e+09  ben reference attached solution one hundred an...   \n",
       "2      0.0  1.583593e+09  dtac called spoke harold software updated prog...   \n",
       "3      0.0  1.583593e+09  dtac hello edward getting error 1057037 please...   \n",
       "4      0.0  1.583593e+09  thanks feedback case us tractor fuel level sho...   \n",
       "\n",
       "      SimW1     SimW2  \n",
       "0  0.445538  0.376947  \n",
       "1  0.390369  0.410178  \n",
       "2  0.441620  0.496341  \n",
       "3  0.394192  0.428796  \n",
       "4  0.600068  0.614462  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EnData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "afb60a5b-05a6-48cc-87bd-6c1cb636c9c6",
    "_uuid": "c900efcd-ffbd-44ce-b2fe-c0a47500d81f"
   },
   "source": [
    "In your case study, you're searching for the documens that are close to the word documents. Therefore, the most relevant documents are those with a small distance value.\n",
    "\n",
    "SortedData1 (SortedData2) represents the data frame that ranks the tests cases from the most similar Word Document1 (Word Document2)) to the less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ae20ded6-5282-4e41-a999-19d995115c77",
    "_uuid": "8cb01c37-9327-4c3c-a1b6-bfeacb1c18ce"
   },
   "outputs": [],
   "source": [
    "SortedData1 =  EnData.sort_values(by=['SimW1'])\n",
    "SortedData2 =  EnData.sort_values(by=['SimW2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "fe495e9f-2aa0-4c22-b3aa-6c11438e181b",
    "_uuid": "b4907631-b0a5-4636-a3cf-185247952afd"
   },
   "outputs": [],
   "source": [
    "SortedData1.to_csv(r'Word1testcases.csv', index = False)\n",
    "SortedData2.to_csv(r'Word2testcases.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
